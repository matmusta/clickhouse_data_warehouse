{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b72baf1",
   "metadata": {},
   "source": [
    "# Similarity Search Benchmarking\n",
    "\n",
    "This notebook generates a synthetic catalog, embeds it with the cached models, and benchmarks several HNSW index configurations for accuracy (recall@k) and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9942da86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/work')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Ensure repository modules are importable and ClickHouse vector support is enabled.\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "if not (project_root / \"python\").exists() and (project_root.parent / \"python\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "python_src = project_root / \"python\"\n",
    "if python_src.exists() and str(python_src) not in sys.path:\n",
    "    sys.path.insert(0, str(python_src))\n",
    "\n",
    "os.environ.setdefault(\"PYTHONPATH\", str(python_src))\n",
    "os.environ.setdefault(\"CLICKHOUSE_ENABLE_VECTOR_EXPERIMENTAL_TYPE\", \"1\")\n",
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e67b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import dependencies used across the benchmark.\"\"\"\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from warehouse import config\n",
    "from warehouse.clickhouse import client_session\n",
    "from warehouse.embeddings import embed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178e1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AppConfig(clickhouse=ClickHouseSettings(host='clickhouse-server', native_port=9000, http_port=8123, user='default', password='clickhouse', database='default'), s3=S3Settings(endpoint_url='http://seaweedfs:8333', region='us-east-1', access_key='s3admin', secret_key='s3secret', bucket='clickhouse-demo'), models=ModelSettings(primary='BAAI/bge-base-en-v1.5', secondary='Alibaba-NLP/gte-Qwen2-1.5B-instruct', active='BAAI/bge-base-en-v1.5'), paths=PathSettings(assets_dir=PosixPath('/home/jovyan/work/assets'), model_cache_dir=PosixPath('/home/jovyan/work/assets/models'), data_dir=PosixPath('/home/jovyan/work/assets/data')))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load the application configuration so we know which hosts and models to target.\"\"\"\n",
    "cfg = config.load_config()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4db74cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>Rechargeable lantern that doubles as a power b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>home</td>\n",
       "      <td>Stackable storage cubes for modular studio org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>books</td>\n",
       "      <td>Climate fiction anthology curated by emerging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>home</td>\n",
       "      <td>Quiet air purifier targeted at open loft layou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>home</td>\n",
       "      <td>Cordless vacuum built for pet-friendly apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  category                                               text\n",
       "0        1  outdoors  Rechargeable lantern that doubles as a power b...\n",
       "1        2      home  Stackable storage cubes for modular studio org...\n",
       "2        3     books  Climate fiction anthology curated by emerging ...\n",
       "3        4      home  Quiet air purifier targeted at open loft layou...\n",
       "4        5      home  Cordless vacuum built for pet-friendly apartme..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Synthesize a reproducible catalog of product-style descriptions.\"\"\"\n",
    "DATASET_SIZE = 600\n",
    "random_seed = random.Random(1337)\n",
    "\n",
    "category_templates: Dict[str, List[str]] = {\n",
    "    \"electronics\": [\n",
    "        \"Wireless earbuds tuned for commuter-friendly noise blocking.\",\n",
    "        \"Compact smart speaker with room-aware adaptive sound.\",\n",
    "        \"Lightweight laptop built for remote-first engineering teams.\",\n",
    "        \"4K action camera ready for cold-weather adventures.\",\n",
    "        \"Portable projector for pop-up backyard movie nights.\",\n",
    "    ],\n",
    "    \"apparel\": [\n",
    "        \"Breathable trail shoes designed for mixed terrain mileage.\",\n",
    "        \"Waterproof shell jacket with recycled performance fibers.\",\n",
    "        \"High-rise leggings that stay opaque through HIIT sessions.\",\n",
    "        \"Classic denim jacket updated with stretch panels.\",\n",
    "        \"Merino hiking socks that regulate temperature on long climbs.\",\n",
    "    ],\n",
    "    \"home\": [\n",
    "        \"Smart thermostat that learns weekly occupancy rhythms.\",\n",
    "        \"Self-watering herb garden for light-starved kitchens.\",\n",
    "        \"Cordless vacuum built for pet-friendly apartments.\",\n",
    "        \"Quiet air purifier targeted at open loft layouts.\",\n",
    "        \"Stackable storage cubes for modular studio organization.\",\n",
    "    ],\n",
    "    \"beauty\": [\n",
    "        \"Vitamin C serum blended for sensitive complexions.\",\n",
    "        \"Matte lipstick that resists mask transfer.\",\n",
    "        \"Hydrating night mask focused on barrier repair.\",\n",
    "        \"Mineral sunscreen that vanishes on deeper skin tones.\",\n",
    "        \"Detox scalp scrub balancing curl-friendly routines.\",\n",
    "    ],\n",
    "    \"outdoors\": [\n",
    "        \"Ultralight backpack sized for fastpacking weekends.\",\n",
    "        \"Carbon trekking poles tuned for alpine approaches.\",\n",
    "        \"Four-season tent with storm-rated ventilation.\",\n",
    "        \"Packable hammock built for riverbank campsites.\",\n",
    "        \"Rechargeable lantern that doubles as a power bank.\",\n",
    "    ],\n",
    "    \"books\": [\n",
    "        \"A space-opera opener following a reluctant diplomat.\",\n",
    "        \"Climate fiction anthology curated by emerging voices.\",\n",
    "        \"Design leadership handbook for distributed product teams.\",\n",
    "        \"Slow-burn mystery set in a remote coastal village.\",\n",
    "        \"Field guide celebrating edible plants of the northeast.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "feature_phrases = [\n",
    "    \"Ships with concierge onboarding and live chat support.\",\n",
    "    \"Pairs with automation recipes shared by the community.\",\n",
    "    \"Arrives in packaging that is fully curbside recyclable.\",\n",
    "    \"Backed by lab-verified durability benchmarks.\",\n",
    "    \"Optimized after A/B testing with power users.\",\n",
    "    \"Configured for quick maintenance swaps in the field.\",\n",
    "    \"Includes lifetime access to the how-to video library.\",\n",
    "]\n",
    "\n",
    "context_phrases = [\n",
    "    \"Frequently bundled with complementary accessories for launch promotions.\",\n",
    "    \"Documented in detail inside the internal runbook for customer success.\",\n",
    "    \"Benchmarked against leading alternatives during the latest GTM sprint.\",\n",
    "    \"Highlighted in usability testing notes from the spring cohort.\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "for item_id in range(1, DATASET_SIZE + 1):\n",
    "    category = random_seed.choice(list(category_templates.keys()))\n",
    "    base = random_seed.choice(category_templates[category])\n",
    "    feature = random_seed.choice(feature_phrases)\n",
    "    description_parts = [base, feature]\n",
    "    if item_id % 17 == 0:\n",
    "        description_parts.append(random_seed.choice(context_phrases))\n",
    "    description = \" \".join(description_parts)\n",
    "    records.append({\"item_id\": item_id, \"category\": category, \"text\": description})\n",
    "\n",
    "dataset_df = pd.DataFrame(records)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cdf5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.88it/s]\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'primary': 768, 'secondary': 1536}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Embed the dataset with both cached models and keep normalized vectors in memory.\"\"\"\n",
    "MODEL_MAP = {\n",
    "    \"primary\": cfg.models.primary,\n",
    "    \"secondary\": cfg.models.secondary,\n",
    "}\n",
    "\n",
    "normalized_embeddings: Dict[str, np.ndarray] = {}\n",
    "embedding_dimensions: Dict[str, int] = {}\n",
    "\n",
    "for label, model_name in MODEL_MAP.items():\n",
    "    vectors = np.asarray(\n",
    "        embed_texts(dataset_df[\"text\"].tolist(), model_name=model_name, config=cfg),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    vectors = vectors / np.clip(norms, a_min=1e-12, a_max=None)\n",
    "    normalized_embeddings[label] = vectors\n",
    "    embedding_dimensions[label] = vectors.shape[1]\n",
    "\n",
    "embedding_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53741b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility helpers to manage ClickHouse tables and evaluate ANN recall/latency.\"\"\"\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IndexSpec:\n",
    "    name: str\n",
    "    params: Dict[str, object]\n",
    "    ef_search: int\n",
    "    description: str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _format_index_literal(value: object) -> str:\n",
    "    \"\"\"Render values as ClickHouse literals for index configuration.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        escaped = value.replace(\"'\", \"''\")\n",
    "        return f\"'{escaped}'\"\n",
    "    if isinstance(value, bool):\n",
    "        return \"1\" if value else \"0\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        return str(value)\n",
    "    raise TypeError(f\"Unsupported index parameter type: {type(value)!r}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _vector_index_expression(dimension: int, spec: IndexSpec) -> str:\n",
    "    \"\"\"Build the vector_similarity(...) expression with optional HNSW overrides.\"\"\"\n",
    "    base_args = [\"'hnsw'\", \"'cosineDistance'\", str(dimension)]\n",
    "    if spec.params:\n",
    "        quantization = spec.params.get(\"quantization\")\n",
    "        m_value = spec.params.get(\"hnsw_max_connections_per_layer\", spec.params.get(\"m\"))\n",
    "        ef_construction = spec.params.get(\n",
    "            \"hnsw_candidate_list_size_for_construction\",\n",
    "            spec.params.get(\"ef_construction\"),\n",
    "        )\n",
    "        if quantization is None and (m_value is not None or ef_construction is not None):\n",
    "            quantization = \"bf16\"\n",
    "        if quantization is not None or m_value is not None or ef_construction is not None:\n",
    "            optional_args = [\n",
    "                _format_index_literal(quantization if quantization is not None else \"bf16\"),\n",
    "                _format_index_literal(m_value if m_value is not None else 0),\n",
    "                _format_index_literal(ef_construction if ef_construction is not None else 0),\n",
    "            ]\n",
    "            base_args.extend(optional_args)\n",
    "    return f\"vector_similarity({', '.join(base_args)})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recreate_vector_table(table_name: str, dimension: int, spec: IndexSpec) -> None:\n",
    "    index_expression = _vector_index_expression(dimension, spec)\n",
    "    create_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        item_id UInt32,\n",
    "        category LowCardinality(String),\n",
    "        embedding Array(Float32),\n",
    "        CONSTRAINT embedding_length CHECK length(embedding) = {dimension},\n",
    "        INDEX idx_embedding_hnsw embedding TYPE {index_expression} GRANULARITY 1\n",
    "    ) ENGINE = MergeTree\n",
    "    ORDER BY item_id\n",
    "    \"\"\"\n",
    "    with client_session(cfg) as client:\n",
    "        client.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        client.execute(create_sql)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def insert_vectors(table_name: str, vectors: np.ndarray) -> None:\n",
    "    payload = [\n",
    "        (\n",
    "            int(row.item_id),\n",
    "            str(row.category),\n",
    "            [float(value) for value in vector],\n",
    "        )\n",
    "        for row, vector in zip(dataset_df.itertuples(index=False), vectors)\n",
    "    ]\n",
    "    with client_session(cfg) as client:\n",
    "        client.execute(\n",
    "            f\"INSERT INTO {table_name} (item_id, category, embedding) VALUES\",\n",
    "            payload,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def drop_table(table_name: str) -> None:\n",
    "    with client_session(cfg) as client:\n",
    "        client.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_ann(\n",
    "    table_name: str,\n",
    "    vectors: np.ndarray,\n",
    "    *,\n",
    "    top_k: int,\n",
    "    query_count: int,\n",
    "    ef_search: int,\n",
    " ) -> Dict[str, float]:\n",
    "    rng = np.random.default_rng(2025)\n",
    "    sample_size = min(query_count, len(vectors))\n",
    "    sample_indices = rng.choice(len(vectors), size=sample_size, replace=False)\n",
    "    latencies_ms: List[float] = []\n",
    "    recalls: List[float] = []\n",
    "\n",
    "\n",
    "    query_sql = f\"\"\"\n",
    "        SELECT item_id, cosineDistance(embedding, %(query_vector)s) AS score\n",
    "        FROM {table_name}\n",
    "        ORDER BY score ASC\n",
    "        LIMIT %(limit)s\n",
    "        SETTINGS hnsw_candidate_list_size_for_search = %(ef_search)s\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with client_session(cfg) as client:\n",
    "        for idx in sample_indices:\n",
    "            query_vector_np = vectors[idx]\n",
    "            query_vector = query_vector_np.tolist()\n",
    "            scores = 1.0 - vectors @ query_vector_np\n",
    "            exact_candidates = np.argpartition(scores, top_k)[:top_k]\n",
    "            ordered = exact_candidates[np.argsort(scores[exact_candidates])]\n",
    "            exact_ids = dataset_df.iloc[ordered][\"item_id\"].tolist()\n",
    "\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            rows = client.execute(\n",
    "                query_sql,\n",
    "                {\"query_vector\": query_vector, \"limit\": top_k, \"ef_search\": ef_search},\n",
    "            )\n",
    "            latency = (time.perf_counter() - start) * 1000.0\n",
    "            latencies_ms.append(latency)\n",
    "\n",
    "\n",
    "            ann_ids = [row[0] for row in rows]\n",
    "            overlap = len(set(ann_ids) & set(exact_ids))\n",
    "            recalls.append(overlap / float(top_k))\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"queries\": float(sample_size),\n",
    "        \"top_k\": float(top_k),\n",
    "        \"mean_recall\": float(np.mean(recalls)),\n",
    "        \"min_recall\": float(np.min(recalls)),\n",
    "        \"mean_latency_ms\": float(np.mean(latencies_ms)),\n",
    "        \"p95_latency_ms\": float(np.percentile(latencies_ms, 95)),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6996b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndexSpec(name='baseline', params={}, ef_search=128, description='ClickHouse defaults (m=16, ef_construction=200, ef_search≈128)'),\n",
       " IndexSpec(name='high_recall', params={'m': 64, 'ef_construction': 800}, ef_search=640, description='Denser graph and higher ef_search for improved recall'),\n",
       " IndexSpec(name='low_latency', params={'m': 8, 'ef_construction': 100}, ef_search=64, description='Smaller graph with reduced ef_search to favor latency')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Define the index configurations and sweep parameters to compare.\"\"\"\n",
    "\n",
    "# ef_search (a.k.a. hnsw_candidate_list_size_for_search): how many neighbors HNSW keeps in its candidate queue while searching. Larger values scan a wider neighborhood, improving recall at the cost of higher latency per query.\n",
    "# m (a.k.a. hnsw_max_connections_per_layer): how many edges each node is allowed to have in the HNSW graph layers. Higher m builds denser graphs that generally yield better recall but take longer to build and consume more memory.\n",
    "# ef_construction (a.k.a. hnsw_candidate_list_size_for_construction): how broad the candidate queue is while the graph is built. Bigger values give the constructor more options when wiring up nodes, leading to higher-quality graphs and better eventual recall, but make ingest/index-build slower.\n",
    "# ef_search during runtime (query setting): same knob as above but applied per query via ClickHouse setting (e.g., SETTINGS hnsw_candidate_list_size_for_search = ...). You can override the default to trade latency for recall without rebuilding the index.\n",
    "\n",
    "index_specs = [\n",
    "    IndexSpec(\n",
    "        name=\"baseline\",\n",
    "        params={},\n",
    "        ef_search=128,\n",
    "        description=\"ClickHouse defaults (m=16, ef_construction=200, ef_search≈128)\",\n",
    "    ),\n",
    "    IndexSpec(\n",
    "        name=\"high_recall\",\n",
    "        params={\"m\": 64, \"ef_construction\": 800},\n",
    "        ef_search=640,\n",
    "        description=\"Denser graph and higher ef_search for improved recall\",\n",
    "    ),\n",
    "    IndexSpec(\n",
    "        name=\"low_latency\",\n",
    "        params={\"m\": 8, \"ef_construction\": 100},\n",
    "        ef_search=64,\n",
    "        description=\"Smaller graph with reduced ef_search to favor latency\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "TOP_K = 10\n",
    "QUERY_COUNT = 500\n",
    "index_specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98bb8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>index_name</th>\n",
       "      <th>description</th>\n",
       "      <th>ef_search</th>\n",
       "      <th>index_params</th>\n",
       "      <th>queries</th>\n",
       "      <th>top_k</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>min_recall</th>\n",
       "      <th>mean_latency_ms</th>\n",
       "      <th>p95_latency_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>primary</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ClickHouse defaults (m=16, ef_construction=200...</td>\n",
       "      <td>128</td>\n",
       "      <td>{}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.600902</td>\n",
       "      <td>6.658008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>primary</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>high_recall</td>\n",
       "      <td>Denser graph and higher ef_search for improved...</td>\n",
       "      <td>640</td>\n",
       "      <td>{'m': 64, 'ef_construction': 800}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.577580</td>\n",
       "      <td>6.919402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>primary</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>low_latency</td>\n",
       "      <td>Smaller graph with reduced ef_search to favor ...</td>\n",
       "      <td>64</td>\n",
       "      <td>{'m': 8, 'ef_construction': 100}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.284843</td>\n",
       "      <td>5.513726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>secondary</td>\n",
       "      <td>Alibaba-NLP/gte-Qwen2-1.5B-instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ClickHouse defaults (m=16, ef_construction=200...</td>\n",
       "      <td>128</td>\n",
       "      <td>{}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.585902</td>\n",
       "      <td>8.981952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secondary</td>\n",
       "      <td>Alibaba-NLP/gte-Qwen2-1.5B-instruct</td>\n",
       "      <td>high_recall</td>\n",
       "      <td>Denser graph and higher ef_search for improved...</td>\n",
       "      <td>640</td>\n",
       "      <td>{'m': 64, 'ef_construction': 800}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.096757</td>\n",
       "      <td>10.207828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>secondary</td>\n",
       "      <td>Alibaba-NLP/gte-Qwen2-1.5B-instruct</td>\n",
       "      <td>low_latency</td>\n",
       "      <td>Smaller graph with reduced ef_search to favor ...</td>\n",
       "      <td>64</td>\n",
       "      <td>{'m': 8, 'ef_construction': 100}</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.914042</td>\n",
       "      <td>10.672908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_label                           model_name   index_name  \\\n",
       "0     primary                BAAI/bge-base-en-v1.5     baseline   \n",
       "1     primary                BAAI/bge-base-en-v1.5  high_recall   \n",
       "2     primary                BAAI/bge-base-en-v1.5  low_latency   \n",
       "3   secondary  Alibaba-NLP/gte-Qwen2-1.5B-instruct     baseline   \n",
       "4   secondary  Alibaba-NLP/gte-Qwen2-1.5B-instruct  high_recall   \n",
       "5   secondary  Alibaba-NLP/gte-Qwen2-1.5B-instruct  low_latency   \n",
       "\n",
       "                                         description  ef_search  \\\n",
       "0  ClickHouse defaults (m=16, ef_construction=200...        128   \n",
       "1  Denser graph and higher ef_search for improved...        640   \n",
       "2  Smaller graph with reduced ef_search to favor ...         64   \n",
       "3  ClickHouse defaults (m=16, ef_construction=200...        128   \n",
       "4  Denser graph and higher ef_search for improved...        640   \n",
       "5  Smaller graph with reduced ef_search to favor ...         64   \n",
       "\n",
       "                        index_params  queries  top_k  mean_recall  min_recall  \\\n",
       "0                                 {}    500.0   10.0       0.9520         0.7   \n",
       "1  {'m': 64, 'ef_construction': 800}    500.0   10.0       0.9512         0.7   \n",
       "2   {'m': 8, 'ef_construction': 100}    500.0   10.0       0.9510         0.8   \n",
       "3                                 {}    500.0   10.0       0.9562         0.7   \n",
       "4  {'m': 64, 'ef_construction': 800}    500.0   10.0       0.9540         0.7   \n",
       "5   {'m': 8, 'ef_construction': 100}    500.0   10.0       0.9410         0.8   \n",
       "\n",
       "   mean_latency_ms  p95_latency_ms  \n",
       "0         4.600902        6.658008  \n",
       "1         4.577580        6.919402  \n",
       "2         4.284843        5.513726  \n",
       "3         6.585902        8.981952  \n",
       "4         7.096757       10.207828  \n",
       "5         6.914042       10.672908  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Run the benchmark sweep across both embedding models and collect metrics.\"\"\"\n",
    "results = []\n",
    "\n",
    "for model_label, model_name in MODEL_MAP.items():\n",
    "    vectors = normalized_embeddings[model_label]\n",
    "    dimension = embedding_dimensions[model_label]\n",
    "    for spec in index_specs:\n",
    "        table_name = f\"benchmark_{model_label}_{spec.name}\"\n",
    "        recreate_vector_table(table_name, dimension, spec)\n",
    "        insert_vectors(table_name, vectors)\n",
    "        metrics = benchmark_ann(\n",
    "            table_name,\n",
    "            vectors,\n",
    "            top_k=TOP_K,\n",
    "            query_count=QUERY_COUNT,\n",
    "            ef_search=spec.ef_search,\n",
    "        )\n",
    "        drop_table(table_name)\n",
    "        entry = {\n",
    "            \"model_label\": model_label,\n",
    "            \"model_name\": model_name,\n",
    "            \"index_name\": spec.name,\n",
    "            \"description\": spec.description,\n",
    "            \"ef_search\": spec.ef_search,\n",
    "            \"index_params\": spec.params,\n",
    "        }\n",
    "        entry.update(metrics)\n",
    "        results.append(entry)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b97cf",
   "metadata": {},
   "source": [
    "Review the table above to pick the configuration that balances recall and latency for your workload. Re-run the benchmark after adjusting index parameters or adding more models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
